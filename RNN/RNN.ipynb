{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421b057c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "$$ z_h^t = W_{xh}x^t + W_{hh}h^{t-1} + b_h $$\n",
    "\n",
    "\n",
    "The above is the pre-activation which is computed through linear combinations \n",
    "\n",
    "$$  h^{(t)}= Tanh(z_h^{(t)}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d158bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c19936",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "rnn_layer = nn.RNN(input_size=5,hidden_size=2,num_layers=1,batch_first=True)\n",
    "w_xh = rnn_layer.weight_ih_l0\n",
    "w_hh = rnn_layer.weight_hh_l0\n",
    "b_xh = rnn_layer.bias_ih_l0\n",
    "b_hh = rnn_layer.bias_hh_l0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b1200a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh shape: torch.Size([2, 5])\n",
      "W_hh shape: torch.Size([2, 2])\n",
      "b_xh shape: torch.Size([2])\n",
      "b_hh shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print('W_xh shape:', w_xh.shape) # Weight matrix for Input->Hidden state\n",
    "print('W_hh shape:', w_hh.shape) # Weight matrix for Hidden reccurence \n",
    "print('b_xh shape:', b_xh.shape) # bias vector for Input->Hidden state\n",
    "print('b_hh shape:', b_hh.shape) # bias vector for Hidden reccurence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3d92130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make our Dataset i.e. input sequence \n",
    "\n",
    "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()\n",
    "\n",
    "x_seq_reshaped = torch.unsqueeze(x_seq,0)\n",
    "x_seq_reshaped.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b52f146f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9817, 0.3122],\n",
       "          [0.9997, 0.8287],\n",
       "          [1.0000, 0.9156]]], grad_fn=<TransposeBackward1>),\n",
       " tensor([[[1.0000, 0.9156]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now have a small dataset with this format (batch, seq, feature) \n",
    "\n",
    "# Output of simple RNN will be \n",
    "\n",
    "output,hn = rnn_layer(x_seq_reshaped)\n",
    "output,hn\n",
    "\n",
    "# We receieved output sequence o0,o1,o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "485f611e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9817, 0.3122], grad_fn=<SelectBackward0>), torch.Size([1, 3, 2]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0] , output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae2f0f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Step 0\n",
      "Input: tensor([1., 1., 1., 1., 1.])\n",
      "Manual Output at time step 0: tensor([0.9817, 0.3122], grad_fn=<TanhBackward0>)\n",
      "Time Step 1\n",
      "Input: tensor([2., 2., 2., 2., 2.])\n",
      "Manual Output at time step 1: tensor([0.9997, 0.8287], grad_fn=<TanhBackward0>)\n",
      "Time Step 2\n",
      "Input: tensor([3., 3., 3., 3., 3.])\n",
      "Manual Output at time step 2: tensor([1.0000, 0.9156], grad_fn=<TanhBackward0>)\n",
      "\n",
      "\n",
      "\n",
      " FINAL OUTPUT: tensor([[[0.9817, 0.3122],\n",
      "         [0.9997, 0.8287],\n",
      "         [1.0000, 0.9156]]], grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Manually foward passing and cross checking it with pytorch output\n",
    "\n",
    "manual_output = []\n",
    "h = torch.zeros(2)\n",
    "for t in range(x_seq_reshaped.shape[1]):\n",
    "    x_t = x_seq_reshaped[0,t]\n",
    "    print(f\"Time Step {t}\")\n",
    "    print(f\"Input: {x_t}\")\n",
    "\n",
    "    h_t = torch.tanh((torch.matmul(w_xh,x_t) + b_xh) + (torch.matmul(w_hh,h) + b_hh))\n",
    "    print(f\"Manual Output at time step {t}: {h_t}\")\n",
    "    \n",
    "    manual_output.append(h_t)\n",
    "    h = h_t\n",
    "\n",
    "\n",
    "manual_output = torch.stack(manual_output, dim=0).unsqueeze(0)\n",
    "\n",
    "print(f\"\\n\\n\\n FINAL OUTPUT: {manual_output}\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a692740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allclose: True\n"
     ]
    }
   ],
   "source": [
    "# should be equal (within numeric tolerance)\n",
    "print(\"allclose:\", torch.allclose(manual_output, output))\n",
    "assert torch.allclose(manual_output, output), \"Manual forward does not match rnn_layer output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a689a",
   "metadata": {},
   "source": [
    "### Pytorch doesn't have weight matrix for hidden-to-output connection (W_ho) or V \n",
    "Hence \n",
    "\n",
    "$$ o^t = h^t $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed288a32",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
